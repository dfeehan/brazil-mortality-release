---
title: "TEMP - figure out what's up with TO"
output: html_notebook
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-packages}
library(networkreporting)
library(tidyverse)
library(here)
library(future)
library(furrr)
library(progressr)
library(tictoc)
```


```{r setup-directories}
data_dir <- here('data')
survey_data_dir <- file.path(data_dir, 'survey')
out_dir <- here('out')
```

# Load the data

```{r load-data}
# load individual data
ego.dat <- read_csv(file.path(survey_data_dir, "individual.csv"))

# load network death data
nr.deaths.dat <- read_csv(file.path(survey_data_dir, "network_reports.csv"))

# load bootstrap weights
#boot.weights <- read_csv(file.path(survey_data_dir, "bootstrap_weights_jab1k.csv.gz"))
#boot.weights <- read_csv(file.path(survey_data_dir, "bootstrap_weights_1k.csv"))
#boot.weights <- read_csv(file.path(survey_data_dir, "bootstrap_weights_10k.csv.gz"))

boot.weights <- readRDS(file.path(survey_data_dir, "bootstrap_weights_10k.rds"))

#boot.weights <- read_csv(file.path(survey_data_dir, "bootstrap_weights_jab10k.csv.gz"))
#boot.weights <- readRDS(file.path(survey_data_dir, "bootstrap_weights_jab10k.rds"))

#boot.weights <- read_csv(file.path(survey_data_dir, "bootstrap_weights_5k.csv.gz"))
#boot.weights <- readRDS(file.path(survey_data_dir, "bootstrap_weights_5k.rds"))

# load frame population sizes
state.dat <- read_csv(file.path(data_dir, "cities.csv"))

all.states <- state.dat %>% pull(state_abbrev)
```

For this analysis, we'll only use reported deaths between the ages of 18 and 65.
We'll filter out people under 18. However, it's a little easier to run the code if we
keep reported deaths who are over 65 for the time being.

```{r drop-unused-deaths}
nr.deaths.dat <- nr.deaths.dat %>%
  filter(agegp10 != '[0,18)')
```


It will be convenient to have a list w/ dataset for each state. We'll do this for
the ego data, the network reports, the known population sizes, and the bootstrap resamples

```{r make-city-data-lists}
# ego data
state.svy <- setNames(map(all.states,
                              function(state) {
                                res <- ego.dat %>% filter(state_abbrev==state)
                                return(res)
                              }),
                      all.states)

# detailed reports about deaths
state.alter.deaths.dat <- setNames(map(all.states,
                                       function(state) {
                                         res <- nr.deaths.dat %>% filter(state_abbrev==state)
                                         return(res)
                                       }),
                                   all.states)

# total size of the known populations in each state
state.kp.tot <- setNames(map(all.states,
                             ~ state.dat %>% 
                               filter(state_abbrev==.x) %>% 
                               pull(total_kp_size)),
                             all.states)

# bootstrap weights
state.bootweights <- setNames(map(all.states,
                               function(state) {
                                 
                                 res <- boot.weights %>% 
                                   filter(state_abbrev==state) %>% 
                                   select(-state_abbrev)
                                 
                                 return(res)
                               }),
                               all.states)
```

get sample sizes

```{r}
resp_dist_plot <- ego.dat %>% 
  filter(! agegp10 %in% c('[65,75)', '[75,Inf]')) %>%
  ggplot(aes(x=agegp10, fill=sex)) +
  geom_bar(position='dodge') +
  xlab("") + ylab("Number of Respondents") +
  facet_wrap(~state_abbrev) +
  theme_minimal()

ggsave(plot=resp_dist_plot, 
       filename=glue::glue("DEBUG_TO/to_debug_resp_counts.png"), width = 15, height = 12)

resp_dist_plot
```
```{r}
resp_cell_dist_plot <- ego.dat %>% 
  filter(agegp10 %in% c('[55,65)'),
         sex == 'male') %>%
  mutate(state_abbrev = fct_infreq(state_abbrev)) %>%
  ggplot(aes(x=state_abbrev)) +
  geom_bar(position='dodge') +
  xlab("") + ylab("Number of Male Respondents [55,65)") +
  theme_minimal()

ggsave(plot=resp_cell_dist_plot, 
       filename=glue::glue("DEBUG_TO/to_debug_cell_resp_counts.png"), width = 10, height = 7)

resp_cell_dist_plot
```

```{r}
# save a .csv of the TO data
write_csv(state.svy[['TO']],
          file = glue::glue("DEBUG_TO/to_debug_survey_responses.csv"))
```


```{r read-cc-data}
survey_data_dir <- file.path(data_dir, 'survey')

cc_file <- "bootstrap_cc_jab10k.rds"
  
boot.cc <- readRDS(file.path(survey_data_dir, cc_file))
```

## Calculate network survival estimates from bootstrap resamples

NB: 1000 bootstrap reps takes about 75 minutes on a 2020 Macbook Pro

NB: 10000 bootstrap reps takes about 49 hours on a 2023 Macbook Pro with 6 cores and 30gb memory allocated via docker

NOTE: this code produces some warnings that look like 
"Bootstrapped degree estimates have 9 out of 14000 values missing. These have been removed in the summary statistics"
These warnings come from older ages, which we don't use in this analysis.

THIS IS ADAPTED FROM THE NETWORK ESTIMATES FILE
IT TOOK ABOUT 6.15 hours (22161 seconds) to run for just TO

```{r network-survival-estimates-bootstrap}
state <- 'TO'

tic("TEMP - current state")
cur.dat <- state.svy[[state]]
cur.deaths.dat <- state.alter.deaths.dat[[state]]
cur.bw <- state.bootweights[[state]] 
# TEMP debug
#cur.bw <- cur.bw[1, c(1, 2000:3000)]
# colnames(cur.bw)[-1] <- paste0("boot_weight_", 1:(ncol(cur.bw)-1))
cur.kp.tot <- state.kp.tot[[state]]

cur.ns <- network.survival.estimator_(resp.data = cur.dat,
                                 attribute.data = cur.deaths.dat,
                                 attribute.names = c('sex', 'agegp10'),
                                 known.populations = 'num_connections_to_kp',
                                 total.kp.size = cur.kp.tot,   
                                 weights = 'weight',
                                 attribute.weights = 'ego.weight',
                                 boot.weights=cur.bw,
                                 within.alter.weights='w.factor.alter',
                                 ego.id=c('id'='ego.id'), 
                                 dropmiss=TRUE,
                                 return.boot=TRUE,
                                 verbose=FALSE)$boot.estimates
cur.ns$state_abbrev <- state
toc()
      
```

```{r}
write_csv(cur.ns, 'DEBUG_TO/to_ests_tmp_debug.csv')
```



NB: boot index 2333 is the one with the extreme asdr estimate

```{r}
cur.ns %>%
  filter(sex == 'male', agegp10 == '[55,65)') %>%
  select(asdr.hat, boot_idx, everything()) %>%
  arrange(-asdr.hat)
```


Look at actual components of estimator

( y(F,D_\alpha) /  y(F_\alpha, \mathcal{A} ) x ( N_{\mathcal{A}} / N_{F} ) 

two things vary w/ bootstrap reps:

- y(F, D_\alpha) => y.F.Dcell.hat
- y(F_\alpha, \mathcal{A}) => y.Fcell.kp.hat

so it's

( y.F.Dcell.hat / y.Fcell.kp.hat) * K 


Look at the distribution of numerators and denominators


```{r}
cur.ns %>%
  filter(sex == 'male', agegp10 == '[55,65)') %>%
  ggplot(.) +
  geom_histogram(aes(x=y.Fcell.kp.hat)) +
  xlab("Num. Reported Connections to KP (in denom.)") +
  theme_minimal()
```

```{r}
cur.ns %>%
  filter(sex == 'male', agegp10 == '[55,65)') %>%
  ggplot(.) +
  geom_histogram(aes(x=y.F.Dcell.hat)) +
  xlab("Num. reported cnxns to deaths (in num.)") +
  theme_minimal()
```

```{r}
cur.ns %>%
  filter(sex == 'male', agegp10 == '[55,65)') %>%
  #mutate(highlight = ifelse(boot_idx == 2333, 'red', 'black')) %>%
  mutate(highlight = ifelse(asdr.hat > .14, 'red', 'black')) %>%
  ggplot(aes(y=y.F.Dcell.hat,
             x=y.Fcell.kp.hat)) +
  geom_point(aes(color = highlight),
             alpha = 0.3) +
  geom_density_2d() +
  ylab("Estimated total deaths in cell") +
  xlab("Estimated total connections to KP from people in cell") +
  scale_color_identity() +
  theme_minimal()
```

So, the high estimates are driven by low reported KP connections and not by high deaths;
when y.Fcell.kp.hat is small, we get the extremely high ASDR estimate

Look at the estimates in descending order of hat(asdr); the highest asdr estimates have 
* N.Fcell.hat of 300, 600, ...
* y.Fcell.kp.hat of 9400, 8140, ...

```{r}
cur.ns %>%
  ungroup() %>% 
  filter(sex == 'male', agegp10 == '[55,65)') %>%
  arrange(-asdr.hat) %>%
  mutate(chk = (y.F.Dcell.hat * total.kp.size) / (y.Fcell.kp.hat * N.F.hat)) %>%
  select(chk, asdr.hat, everything())
```

OK, so I think we understand that the high variance in ASDR estimates comes from a few resamples where the total connections to KP from older males is low

TODO - want to be able to connect this to PSUs / Jackknife after bootstrap ...

```{r}
# get the brazil project directories for this computer 
source(path.expand(file.path("~", "brazil-directories", "directories.r")))
set.dirs()       

## set the seed to make results replicable
set.seed(101010101)


## maps the survey ids to anonymized hashes
id_map <- read_csv(file.path('/home/rstudio/brazil-group/data', "id_hashes.csv"))
id_to_cb_map <- read_csv(file.path('/home/rstudio/brazil-group/data', "cb_map.csv"))

```

Join PSU info on...

```{r}
cur.dat.withpsu <- cur.dat %>% 
  left_join(id_map) %>%
  mutate(release_id = id) %>%
  mutate(id = paste(raw_id)) %>%
  left_join(id_to_cb_map %>% mutate(id = paste(id)))

write_csv(cur.dat.withpsu, '../to_ests_tmp_withcb.csv')
```

TODO - LEFT OFF HERE

- I want to get num / denom contribution from each PSU
- I think the PSUs with no old men are being dropped somehow; there should be ~100 PSUs,
  but I'm only getting ~ 13, I think
- maybe what is happening is that some boot resamples have very few of these PSUs with any old men?

```{r}
psu_summ <- 
  cur.dat.withpsu %>%
    filter(state_abbrev == 'TO') %>%
    filter(! is.na(num_connections_to_kp)) %>%
    mutate(is_in_cell = as.numeric(sex == 'male' & agegp10 == '[55,65)')) %>%
    group_by(cb_code,.drop=FALSE) %>%
    summarize(tot_n = sum(is_in_cell),
              tot_wgt = sum(weight),
              tot_connections_to_kp = sum(is_in_cell*num_connections_to_kp),
              wgt_connections_to_kp = sum(is_in_cell*weight * num_connections_to_kp))

psu_summ
```

ALSO - let's visualize which PSUs are / are not included in each bootstrap resample

```{r}
boot.cc.to.long <- boot.cc %>% 
  filter(state_abbrev == 'TO') %>%
  select(-state_abbrev, -geo) %>%
  ## TRANSPOSE so that boot reps are rows and PSUs are columns
  pivot_longer(cols = -1) %>%               # Stack all columns except the first one
  pivot_wider(names_from = 1,               # Use the first column's values as new headers
              values_from = value,
              names_prefix = 'cb_') %>%
  mutate(boot_idx = parse_number(name)) %>%
  select(-name) %>%
  ## join on the ASDR estimate for each bootstrap resample 
  left_join(cur.ns %>%
            ungroup() %>% 
            filter(sex == 'male', agegp10 == '[55,65)') %>%
            select(boot_idx, asdr.hat) ) %>%
  select(boot_idx, asdr.hat, everything())

```


```{r}
#min_idx <- 2300
#max_idx <- 2400

slice_size <- 200

#asdr_factor <- 1
#fnabbrev <- 'lowest'
#cluster <- FALSE

asdr_factor <- -1
fnabbrev <- 'highest'
cluster <- TRUE

name <- glue::glue("{fnabbrev} ASDR estimates")

# 1. Extract the matrix of just the cb_ columns
mat <- boot.cc.to %>%
  # TRYING THIS
  arrange(asdr_factor*asdr.hat) %>%
  #slice(min_idx:max_idx) %>%
  slice(1:slice_size) %>%
  select(starts_with("cb_")) %>%
  as.matrix()

# 2. Run a simple clustering algorithm on columns
if(cluster) {
cluster_cols <- hclust(dist(t(mat))) 
ordered_col_names <- cluster_cols$labels[cluster_cols$order]
}

# 3. Use that order for the plot
for_plot <- boot.cc.to %>%
  #slice(min_idx:max_idx) %>%
  arrange(asdr_factor*asdr.hat) %>%
  slice(1:slice_size) %>%
  arrange(asdr.hat) %>%
  mutate(boot_idx = factor(boot_idx, levels = boot_idx)) %>%
  select(boot_idx, all_of(ordered_col_names)) %>% # Select in clustered order
  pivot_longer(cols = -boot_idx, names_to = "cell_id", values_to = "value") %>%
  mutate(cell_id = factor(cell_id, levels = ordered_col_names))

hm <- for_plot %>%
  ggplot(., aes(x = cell_id, y = boot_idx, fill = value)) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c() +                   # Nice color blind friendly palette
  theme_minimal() +
  theme(
    #axis.text.x = element_blank(),           # Hide X labels (too many of them)
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(angle=90, size=3),           # Hide X labels (too many of them)
    axis.text.y = element_text(size=3),
    panel.grid = element_blank()
  ) +
  labs(
    title = glue::glue("Heatmap of Bootstrap Reps {slice_size} {name}"),
    #x = "Columns (cb_...)",
    y = "Bootstrap Index"
  )  

ggsave(plot=hm, 
       filename=glue::glue("DEBUG_TO/to_debug_psu_heatmap_{fnabbrev}_asdr.png"), width = 15, height = 15)

hm
```




```{r}
cb_chk <- '0e1df638'

psu_summ %>%
  filter(cb_code == cb_chk)
```
Out of 101 total PSUs, 88 of them don't have any interviews w/ older men

```{r}
psu_summ %>%
  filter(tot_n == 0)
```


Let's also look at reported deaths in the cell by PSU...

```{r}
nr.deaths.cell.to.withpsu <-
  nr.deaths.dat %>%
  filter(state_abbrev == 'TO') %>%
  filter(sex == 'male',
         agegp10 == '[55,65)') %>%
  left_join(cur.dat.withpsu %>% select(ego.id = release_id, cb_code))
```

```{r}
psu_summ_all <- psu_summ %>%
  left_join(
    nr.deaths.cell.to %>%
      group_by(cb_code) %>%
      summarize(tot_rep_deaths = n(),
                wgt_rep_deaths = sum(ego.weight*w.factor.alter))
  ) %>%
  mutate(tot_rep_deaths = ifelse(is.na(tot_rep_deaths), 0, tot_rep_deaths),
         wgt_rep_deaths = ifelse(is.na(wgt_rep_deaths), 0, wgt_rep_deaths))
```

```{r}
library(tidyverse)

# 1. Prepare the summary data
# We use the 'ordered_col_names' vector from the Clustering step 
# or the 'col_order' vector from the Column Sums step.
psu_counts <- psu_summ_all %>%
  mutate(cb_code = paste0('cb_', cb_code)) %>%
  # Filter to only include codes present in your heatmap/ordered list
  filter(cb_code %in% ordered_col_names) %>% 
  # Lock the order to match the heatmap
  mutate(cb_code = factor(cb_code, levels = ordered_col_names)) %>%
  # Pivot the two variables so they can be distinguished by color
  pivot_longer(
    cols = c(tot_connections_to_kp, 
             tot_rep_deaths, 
             tot_wgt),
    names_to = "metric",
    values_to = "count"
  )

# 2. Create the plot
psu_counts_plot <- ggplot(psu_counts, 
                          aes(x = cb_code, 
                              y = count, 
                              color = metric, 
                              shape = metric,
                              group = metric)) +
  geom_point(size = 2) +              # Points help see individual PSU values
  theme_minimal() +
  theme(
    #axis.text.x = element_blank(),     # Hide labels to match heatmap style
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(angle=90, size=5),           # Hide X labels (too many of them)
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  ) +
  scale_color_brewer(palette = "Set1", labels = c("Connections to KP", "Rep. Deaths", "Tot. Weight")) +
  scale_shape(labels = c("Connections to KP", "Rep. Deaths", "Tot. Weight")) +
  labs(
    x = "",
    y = "Count",
    color = "Variable", shape = 'Variable'
  ) +
  facet_grid(metric ~ ., scales='free_y')

ggsave(plot=psu_counts_plot, 
       filename=glue::glue("DEBUG_TO/to_debug_psu_psu_counts.png"), width = 15, height = 10)
  
psu_counts_plot
```

```{r}

hm / psu_counts_plot + plot_layout(heights = c(15, 1))

```










